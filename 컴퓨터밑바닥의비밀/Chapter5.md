# 컴퓨터 구조의 비밀 8주차

# 5.1 캐시, 어디에나 존재하는 것

폰 노이만 구조는 CPU가 실행하는 **기계 명령어와 명령어가 처리하는 데이터가 모두 메모리에 저장되어 있어야 한다**는 사실을 알려준다. 레지스터 용량은 극히 제한되어 있다. CPU는 반드시 **빈번하게 메모리에 접근**하여 명령어와 데이터를 가져와야 한다.

## 5.1.1 CPU와 메모리 속도 차이

CPU와 메모리는 탄생 직후부터 시간이 지날수록 속도 차이가 점점 벌어지고 있다. 메모리는 얼마나 느린가? 마니 느림.. CPU의 100분의 1에 불과하다.

[키워드 : CPU와 메모리의 속도차이(메모리가 느림) ]

## 5.1.2 도서관, 책상, 캐시

책상: 캐시

서가 : 메모리

캐시가 적중하면 메모리에 접근할 필요가 없어 CPU가 명령어를 실행하는 속도를 크게 끌어올리는 목적을 쉽게 달성할 수 있다. **CPU는 직접 메모리를 읽고 쓰지 않기 때문에** CPU와 메모리 사이의 속도 차이를 보완할 수 있다.

x86같은 최신 CPU와 메모리 사이엔 실제로 세단계의 캐시가 추가되어있다. 캐시 단계에 따라 접근속도는 낮아지지만 용량은 증가한다.

(적중하라.. 밑으로 쭉쭉 내려감)

오늘날 **CPU칩에서 상당 부분의 공간을 캐시가 차지하고 있으며,** 실제로 기계 명령어를 실행하는 CPU코어가 차지하는 공간은 그리 크지 않다.

[키워드: CPU칩 캐시 공간, 캐시 적중]

### 5.1.3 공짜 점심은 없다: 캐시 갱신

캐시가 있기 때문에 CPU는 더 이상 메모리와 직접 일하지 않으며 CPU는 캐시에 직접 기록한다.

**문제 :** 불일치 (캐시 변수값 4 메모리 변수값2)

**해결법 :** 연속기입. 캐시 갱신시 메모리도 함께 갱신 (메모리에 접근해야함)

CPU가 메모리 기록할떄는 캐시 직접 갱신, 이때 반드시 메모리 갱신이 완료되길 기다릴 필요 없이 CPU는 바로 다음 명령어 실행 가능. 그렇다면 캐시 최신 데이터는 언제 메모리에 갱신 되는 것일까 ?

캐시 용량에도 한계가 있어 용량이 부족하면 반드시 자주 사용되지 않는 데이터를 제거해야한다. 이때 캐시에서 제거된 데이터가 수정된 적이 있다면 이를 메모리에 갱신해야 한다. 이렇게 **캐시의 갱신과 메모리의 갱신이 분리**되므로 이 방식은 비동기에 해당하며, 이를 **후기입** 이라고 한다. (연속기입보다 복잡하지만 성능은 더 나음)

[ 키워드: 불일치, 연속기입, 후기입 ]

### 5.1.4 다중 코어 캐시의 일관성

CPU 성능은 쉽게 향상되지 않지만 그 숫자를 늘릴 수는 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5a26ec9a-4a75-431e-ae2d-b908cda9c589/2ef9a318-d5a2-4990-beb2-5f86b9a355eb/Untitled.png)

CPU가 코어 여러 개를 가지고 있다면 또 다른 문제가 발생한다. 시스템에 CPU코어 두 개가 있다면, 이 두 코어에서는 서로 다른 스레드 두 개가 실행된다.

**전제 :** 두 스레드가 모두 메모리 내 x변수에 접근해야 하고 변수 초기값이 2

**해결 방법 :** 캐시 한 개에서 갱신된 변수가 다른 CPU 코어의 캐시에도 존재한다면 이 캐시도 함께 갱신되어야 한다. CPU는 변수 업데이트시 단순히 자체 캐시와 메모리만 신경 쓰는 것이 아닌, 해당 변수가 **다른 CPU 코어의 캐시에도 있는지 확인**하고, 있다면 해당 캐시에도 갱신해야 한다.

### 5.1.5 메모리를 디스크의 캐시로 활용하기

디스크……… 매우 느림

왜 메모리를 직접 디스크의 캐시로 사용하지 않을까 ?

⇒ 레지스터가 메모리의 캐시가 될 수 없는 이유는 **레지스터 크기가 한정되어 있기 때문.**

최신 운영체제는 메모리를 디스크의 캐시로 사용. 캐시가 추가되면 반드시 캐시 갱신 문제가 발생.

최근 메모리가 디스크를 대체하는 것이 대세. 이유는 메모리가 점점 더 저렴해지고 있기 때문.

### 5.1.6 가상 메모리와 디스크

시스템에 프로세스 N개가 있을 때, 이 프로세스 N개가 실제 물리 메모리를 모두 사용하고 있을 때, 새로운 프로세스가 생성되어 이 N + 1 번째 프로세스도 메모리를 요청한다고 가정. 시스템은 이를 어떻게 처리할 수 있을까 ?

⇒ 안쓰는거 내림 ㅇㅇ

자주 사용하지 않은 메모리 데이터를 디스크에 기록하고 이 데이터가 차지하던 물리 메모리 공간을 해제한다. 운영체제 열일중

### 5.1.7 CPU는 어떻게 메모리를 읽을까 ?

CPU가 볼 수 있는 것은 모두 가상 메모리 주소이다. 모두 물리 메모리 주소로 변환되어야 한다.

단일 장치 디스크만으로 큰 데이터 저장할 수 없어!!!! 어떻게 하지

### 5.1.8 분산 저장 지원

대용량 데이터 문제? ⇒ 한대 부족하면 여러대 사용해 = 분산 파일 시스템

# 5.2 어떻게 캐시 친화적인 프로그램을 작성할까 ?

L1 L3로 갈수록 용량은 커지지만 접근 속도는 점점 느려진다.

### 5.2.1 프로그램 지역성의 원칙

**지역성의 원칙:** 매우 규칙적으로 메모리에 접근

**시간적 지역성** : 메모리 조각에 접근하고 이 조각을 여러번 참조

- for, while 같은 반복문을 예로 들 수 있다. 특정 부분을 반복해 접근하기 때문에 다시 참조할 확률이 높다.

**공간적 지역성 :** 인접한 메모리 참조

- 배열을 예로 들 수 있다. 인덱스 연속 접근 같은 경우 그 다음 원소들에 접근 가능성이 높다.

### 5.2.2 메모리 풀 사용

## 5.3 다중 스레드 성능 방해자

### 5.3.1 캐시와 메모리 상호 작용의 기본 단위 : [캐시 라인](https://rebro.kr/180)

프로그램의 공간적 지역성 원리는 어떤 의미가 있을까 ?

묶음 데이터는 캐시 라인 이라는 이름을 갖고 있으며, 이 이름은 데이터 한 줄 이라는 의미가 있다. **캐시와 메모리 상호 작용의 기본 단위**는 **캐시 라인**이다. 이 묶음 데이터의 크기는 일반적으로 64바이트이며, 캐시가 적중하지 못하면 이 묶음 데이터가 캐시에 저장된다.

\*캐시 메모리는 메인 메모리에 비해 크기가 매우 작기 때문에 메인 메모리와 1:1 매칭이 불가능하다.

캐시가 아무리 CPU에 가깝게 위치하더라도, 데이터가 캐시 내의 어느 곳에 저장되어 있는지 찾기가 어려워 모든 데이터를 순회해야 한다면 캐시의 장점을 잃기 때문에 쉽게 찾을 수 있는 구조가 필요하다. 따라서,캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 묶음으로 저장하는데 이를 **캐싱 라인(Caching Line)**이라고 한다. 빈번하게 사용되는 데이터의 주소들이 흩어져 있기 때문에 캐시에 저장하는 데이터에는 데이터의 주소 등을 기록해둔 태그를 달아둘 필요가 있다. 캐시라인이라는건 그냥 **캐시의 값이 어떤 메모리주소에서 가져왔는지 표시하는거고** 그게 tag이다.

### 5.3.2 첫 번째 성능 방해자: 캐시 튕김 문제

코드 요약 :

1. 각 스레드는 전역변수 a의 값을 1씩 5억번 증가 (병렬) (16초)
2. 단일 스레드는 전역변수 a값을 1씩 10억번 증가 (단일) (8초)

다중 스레드 프로그램의 insn per cycle → 0.15

단일 스레드 프로그램 insn per cycle → 0.6

단일 스레드 프로그램에서 a 변수를 일반적인 int 형으로 정의하면 실행 시간은 더욱 빨라져 컴퓨터에서 다중 스레드보다 여덟 배 빠른 2초 만에 실행이 완료된다. 즉, 클럭 주기 한 번에 기계 명령어를 하나 이상 실행할 수 있다.

_병렬 계산임에도 불구하고 다중 스레드가 단일스레드보다 느린 이유는 ?_

→ 캐시를 유지하는데 드는 부담과 메모리에서 **매번 새로 데이터를 읽어오는 부담**이 전체 흐름을 방해할 만큼 매우 커서 이런 다중 스레드 프로그램의 성능은 단일 스레드 프로그램의 성능에 미치지 못한다.

_어떤 변수를 공유하지도 않아도 다중 스레드가 느릴 수 있는 이유 ?_

⇒ 두 변수가 **동일한 캐시 라인에 있을 가능성**이 매우 높다. (두 변수가 하나의 캐시 라인을 공유하고 있을 수 있다.) 캐시와 메모리는 캐시 라인 단위로 상호 작용을 한다.

**결론 :** 비록 스레드 두 개가 어떤 데이터도 공유하지 않는 것처럼 보이더라도 캐시의 동작 방식에 따라 캐시 라인을 공유할 가능성이 있다. (이것을 거짓 공유라고한다.) 이 역시 캐시 튕김 문제를 발생시킨다.

**해결방법** : 두 변수 사이에 사용되지 않는 데이터를 채운다.

a변수와 b변수 사이에 요소 16개를 가진 int형식의 배열을 채운다.

변수 순서를 조정한다.

**다중 스레드 프로그램의 성능 방해자:**

1. 캐시 팅김 문제
2. 거짓 공유 문제

```java
struct data
{
int a
int arr[16]
int b
}

```

이 구조체를 메모리에 배치하면 전체 크기는 4바이트 (a) + 64바이트 (arr) + 4바이트 (b) = 72바이트

캐시 라인은 64바이트입니다.

구조체 `data`를 캐시 라인에 맞추어 배치하면:

- `a`는 첫 4바이트에 저장됨
- `arr[16]`는 그 다음 64바이트에 저장
- `b`는 `arr` 이후의 4바이트에 저장됨

따라서,각 코어가 다른 캐시 라인에서 작업하므로 캐시 일관성을 유지하기가 더 쉬워진다. 결론적으로, `a`와 `b`가 배열에 의해 분리되어 서로 다른 캐시 라인에 위치하게 된다는 말은, 캐시 라인의 크기와 배열의 크기 때문에 `a`와 `b`가 물리적으로 떨어져 다른 캐시 라인에 배치된다는 뜻이다. (이해완!!!)

a는 첫 번째 캐시 라인에 들어감
arr[16]도 첫 번째 캐시 라인에 들어감
b는 두 번째 캐시 라인에 들어감

## 5.4 봉화희제후와 메모리 장벽

제후 스레드 안에서 n값은 얼마냐..

⇒ 100000일수도 0 일수도 ? x86에서 값이 다를 수도 ?!

### 이 안에서 a와 b의 마지막 값은 얼마일까용 ?

```java
- 전제: X와 Y 변수 모두 초기값 0임

스레드 1 / X=1 a=Y
스레드 2 / Y=1 b=X
```

1. 스레드 1이 먼저 실행되며, 이때 a=0, b=1
2. 스레드 2가 먼저 실행되며, 이때 a=1, b=0
3. 스레드 1과 스레드 2가 동시에 코드의 첫 줄을 실행하며, 이때 a=1, b=1

우리에게 익숙한 x86플랫폼에서는 이 코드가 실행된 후에 a와 b 모두가 0일수도 ㄷㄷ

이게 어떻게 가능할까 ………………

## 5.4.1 명령어의 비순차적 실행: 컴파일러와 OoOE

CPU실행순서는 비순차적.

모든 것은 성능과 항상 직결된다.

명령어의 비순차적 실행은 다음과 같이 두 단계를 거친다.

1. **기계 명령어를 생성하는 단계:** 컴파일 중에 명령어를 재정렬
2. **CPU가 명령어를 실행하는 단계:** 실행 중에 명령어가 비순차적으로 실행

### CPU작업 과정

1. 기계 명령어 가져옴
2. 명령어의 피연산자가 레지스터에 저장되는 등 이미 준비 완료 상태라면 명령어는 실행단계에 들어감.
3. 데이터가 준비됐다면 명령어 실행
4. 실행결과 기록

장점: 매우 직관적

문제: 피연산자가 준비되지 않았더라면 CPU가 반드시 대기해야 하기 때문에 비효율적

### 해결책

1. 기계 명령어 가져옴
2. 명령어 대기열에 넣고 명령어에 필요한 피연산자 가져옴
3. 명령어는 대기열에서 피연산자 준비 완료될때까지 대기. 준비 완료된 명령어는 먼저 실행단계 들어감.
4. 기계 명령어 실행하면 실행 결과 대기열에 넣음

CPU와 메모리 속도 차이는 엄청나다. 순차적으로 실행하면 파이프라인 내부 공간에 빈공간인 슬롯이 생긴다. 그 공간을 메꾼다면 실행 속도를 확실히 끌어올릴 수 있다. 비순차적 명령어 실행 기능이 있는 CPU에서는 명령어가 비순차적으로 실행될 수 있지만 모든 CPU가 가지고 있는 것은 아님.

## 5.4.2 캐시도 고려해야 한다

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5a26ec9a-4a75-431e-ae2d-b908cda9c589/40de1258-d100-4342-92f9-21558c7dcd62/Untitled.png)

L1, L2캐시는 각각 CPU코어마다 별도로 존재. L3캐시와 메모리는 모든 코어가 공유.

어떻게 캐시를 갱신하고 어떻게 일관성을 유지 시킬 것인가. 이 과정을 최적화 하기 위해 일부 시스템은 저장 버퍼등 대기열을 추가한다. 기록 작업이 있을 때 대기열에 직접 기록하기 때문에 캐시는 즉시 갱신되지 않는다. CPU는 캐시가 갱신되기를 기다리지 않고 다음 명령어를 계속 실행할 수 있다.

CPU가 실행하는 명령어를 비교할 때 기록 작업은 비동기 과정이다.

```java
전제: a변수의 초기값은 0, y변수의 초기값은 100
a=1
b=y
```

[ 키워드 : L1-3, ]

## 5.4.3 네 가지 메모리 장벽 유형 [다중 코어 시스템에서 메모리 접근 순서를 제어]

> 메모리 장벽은 CPU가 명령어의 순서를 변경하지 못하게 하는 지시어

1. **LoadLoad**

부정 출발 형태로 먼저 실행되는 것을 방지

1. **StoreStore**

CPU가 Store 명령어를 실행할 때 Store 명령어가 부정 출발 형태로 먼저 실행 되는 것을 방지

이 메모리 장벽을 추가하게 되면 다른 코어에서 보기에 변수의 갱신 순서와 코드 순서가 일치하게 된다.

1. **LoadStore**

쓰기 작업은 상대적으로 무겁다. 어떻게 Load 명령어보다 먼저 실행될 수 있을까 ?

Load 명령어가 캐시에 적중하지 못하면 일부 CPU에서는 다음에 오는 **Store 명령어가 먼저 실행될 수 있다.**

_로드 명령어가 완료되기 전까지 저장 명령어가 실행되지 않도록. 이 장벽이 없으면, 만약 로드 명령어가 캐시에 적중하지 못하고 메모리에서 데이터를 가져와야 하는 상황에서 CPU는 저장 명령어를 먼저 실행할 수 있다._

```java
void thread_zhuzhou()
{
    int n;
    int important;

    if(is_enenmy_comming){
        LoadLoad_FENCE(); // 로드로드 메모리 장벽
        n = enenmy_num;
        important = 10; // 반드시 봉화 신호가 보일때까지 기다려야 실행 가능
    }
}

```

1. **StoreLoad (본질적으로 메모리 장벽은 동기 작업)**

CPU가 부정 출발 형식으로 **읽기 명령어를 먼저 실행하는 것을 방지. 네가지 메모리 장벽 중에서 가장 무겁다.**

CPU가 쓰기 명령어를 실행할 때 해당 쓰기 명령어에 필요한 작업이 얼마나 복잡하든 대기해야 하는 시간이 얼마나 길든 간에 이 유휴 시간 동안 CPU는 다음에 오는 관련 없는 읽기 작업을 미리 실행할 수 없으며, StoreLoad 메모리 장벽 이전에 쓰기 작업이 모든 다른 코어에서 반드시 확인 가능해야 한다.

⇒ 최신 값 보장 가능 !

**[ StoreStore와의 차이 ]**

StoreStore: 다른 코어가 메모리 장벽 이전의 변수를 읽었을 때 곧바로 최신의 값이라는 것을 보장하지 않는다.

갱신 순서와 코드 순서가 일치하는 것만 보장하며, 다른 코어가 즉시 최신 값을 확인하는 것은 보장하지 않는다.

## 5.4.4 획득 - 해제 의미론

다중 스레드 프로그래밍 사용할때 보통 문제 직면

1. 공유 데이터 **\*상호 배타적** 접근
2. 스레드 간 동기화 문제

획득 의미론은 메모리 읽기 작업에 대한 것

### 상호 배타적 접근

- 여러 프로세스나 스레드가 동시에 공유 자원 (예: 데이터, 파일, 메모리 등) 에 접근하지 못하도록 하는 메커니즘을 의미

### 상호배제

상호 배제(相互排除, mutual exclusion, Mutex, 뮤텍스)는 **동시 프로그래밍에서 공유 불가능한 자원의 동시 사용을 피하기 위해 사용되는 알고리즘**

## 5.4.5 C++ 에서 제공하는 인터페이스

x86에서 실제로 StoreLoad 재정렬만 발생할 수 있다.

특정 유형의 CPU 대상으로만 코드를 작성하면 ARM 플랫폼에 이식할 방법 X

## 5.4.7

한마디로 잠금 없는 프로그래밍을 해야할 때만 명령어 재정렬에 신경 쓰면 된다.

일반적으로 잠금은 공유변수 보호에 사용됨.

잠금하면 스레드는 앞으로 나아갈 수 없음.

**스핀 잠금 :** 해당 잠금이 사용된 후 잠금을 요청하는 스레드는 계속 잠금이 해제되었는지 여부를 반복적으로 확인함. 이때 잠금을 요청하는 다른 스레드는 운영체제에 의해 **대기 상태로 진입하지 않음.**

잠금 없는 프로그래밍은 시스템 성능 향상에 사용되지 않고, 스레드가 항상 대기 없이 어떤 일을 하도록 하는 것에 가치를 두고 있음.

### 재정렬 문제

- 재정렬 문제(Reordering Issue)는 컴퓨터 시스템에서 코드의 실행 순서가 프로그래머가 작성한 순서와 다르게 수행되는 현상

# 5.5 요약

이론적으로 캐시는 필요없음.

하지만 시대가 발전해가면서 CPU와 메모리 성능 격차가 너무 많이 벌어짐.
